---
noteId: "38716fb0751611eabc1627f679e258ca"
tags: []

---

# Course description
This is a graduate-level course on optimization. The course covers mathematical programming and combinatorial optimization from the perspective of convex optimization, which is a central tool for solving large-scale problems. In recent years convex optimization has had a profound impact on statistical machine learning, data analysis, mathematical finance, signal processing, control, theoretical computer science, and many other areas. The first part will be dedicated to the theory of convex optimization and its direct applications. The second part will focus on advanced techniques in combinatorial optimization using machinery developed in the first part.


## Course Outline

Prelude
Optimization as a foundation for data science
Convex sets, convex functions
Projection, separating hyperplanes, polyhedral sets
Linear Optimization
Farkas' lemma
Duality theory
The Simplex method
Ellipsoid, and interior point methods
Convex Optimization
Gradient descent
Newton's method and its variants
Karush-Kuhn-Tucker conditions
Lagrangian duality
Semi-definite programming
Combinatorial Optimization
Computational complexity
Approximation algorithms
Submodular functions
Local search and greedy algorithms
Dynamic Programming
Matroids, multilinear extensions, convex and concave closures
Rounding techniques
Continuous approximation algorithms



## Resources
The class is self contained, and will not follow a specific book. The material of the course is largely covered in the following textbooks:

Convex Optimization, by Boyd and Vandenberghe
Introduction to Linear Optimization, by Bertsimas and Tsitsiklis
The Design of Approximation Algorithms, by Williamson and Shmoys
In addition, we also recommend consulting these textbooks:
Approximation Algorithms, by Vazirani
Integer and Combinatorial Optimization, by Nemhauser and Wolsey
The Elements of Statistical Learning, by Hastie, Tibshirani and Friedman

## Docs
http://people.seas.harvard.edu/~yaron/AM221-S16/